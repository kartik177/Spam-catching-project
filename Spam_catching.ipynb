{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam catching.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWhJ1bhk12Mw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xJ-djlJ2AHh"
      },
      "source": [
        "The **Classifer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03vwSNjS2Egk"
      },
      "source": [
        "def extract_features(self,\n",
        "                     labels: pd.Series,\n",
        "                     docs: pd.Series) -> pd.DataFrame:\n",
        "     \"\"\"| Create dataframe where each row is a document and each column\n",
        "        | is a term, weighted by TF-IDF (term frequency - inverse document\n",
        "        | frequency). Lowercases all words, performs lemmatization,\n",
        "        | and removes stopwords and punctuation.\n",
        "        |\n",
        "        | ----------------------------------------------------------------\n",
        "        | Parameters\n",
        "        | ----------\n",
        "        |  labels : pd.Series\n",
        "        |    Ham/spam classification\n",
        "        |\n",
        "        |  docs : pd.Series\n",
        "        |    Documents to extract features from\n",
        "        |\n",
        "        |\n",
        "        | Returns\n",
        "        | -------\n",
        "        |  pd.DataFrame\n",
        "        \"\"\"\n",
        "    \n",
        "    if not self.tfidf_vectorizer:\n",
        "          self.set_tfidf_vectorizer(docs)\n",
        "      # Transform documents into TF-IDF features\n",
        "      features = self.tfidf_vectorizer.transform(docs)\n",
        "\n",
        "    # Reshape and add back ham/spam label\n",
        "    feature_df = pd.DataFrame(features.todense(),\n",
        "                              columns=self.tfidf_vectorizer.get_feature_names())\n",
        "    feature_df.insert(0, 'label', labels)\n",
        "\n",
        "    return feature_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu8waqV92I9-"
      },
      "source": [
        "import pandas as pd\n",
        "def train_model(self,\n",
        "                df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    | Train a random forest classifier on df. Assumes first column\n",
        "    | is labels and all remaining columns are features. Updates\n",
        "    | self.model, self.accuracy, and self.top_features\n",
        "    |\n",
        "    | ------------------------------------------------------------\n",
        "    | Parameters\n",
        "    | ----------\n",
        "    |  df : pd.DataFrame\n",
        "    |    The data, where first column is labels and remaining columns\n",
        "    |    are features\n",
        "    |\n",
        "    |\n",
        "    | Returns\n",
        "    | -------\n",
        "    |  None\n",
        "    \"\"\"\n",
        "    X = df.iloc[:, 1:]\n",
        "    y = df.iloc[:, 0]\n",
        "\n",
        "    # Set spam as target\n",
        "    y.replace({'ham': 0, 'spam': 1}, inplace=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=100)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    self.model = rf\n",
        "    self.accuracy = round(accuracy_score(rf.predict(X_test), y_test), 4)\n",
        "    self.top_features = self._get_top_features(list(X_train))\n",
        "    return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV6-t822Xvh"
      },
      "source": [
        "def set_model(self,\n",
        "              save_on_new: bool = True) -> None:\n",
        "    \"\"\"\n",
        "    | Set self.model. Uses existing model at MODEL_PATH if one exists,\n",
        "    | otherwise calls self.load_and_train. Model saved to MODEL_PATH\n",
        "    | if save_on_new is True.\n",
        "    |\n",
        "    | ---------------------------------------------------------------\n",
        "    | Parameters\n",
        "    | ----------\n",
        "    |  save_on_new : bool\n",
        "    |    If self.load_and_train invoked, whether the new model should\n",
        "    |    be saved to MODEL_PATH\n",
        "    |\n",
        "    |\n",
        "    | Returns\n",
        "    | -------\n",
        "    |  None\n",
        "    \"\"\"\n",
        "    if os.path.isfile(MODEL_PATH):\n",
        "        logging.debug(f\"Using existing model at {MODEL_PATH}\")\n",
        "        with open(MODEL_PATH, \"rb\") as input_file:\n",
        "            obj = pickle.load(input_file)\n",
        "            self.tfidf_vectorizer = obj['tfidf_vectorizer']\n",
        "            self.model = obj['model']\n",
        "            self.accuracy = obj['accuracy']\n",
        "            self.top_features = obj['top_features']\n",
        "\n",
        "    else:\n",
        "        logging.debug(f\"No model at {MODEL_PATH}; training new model\")\n",
        "        self.load_and_train()\n",
        "\n",
        "        if save_on_new:\n",
        "            logging.debug(f\"Saving new model to {MODEL_PATH}\")\n",
        "            with open(MODEL_PATH, \"wb\") as output_file:\n",
        "                pickle.dump(vars(self), output_file)\n",
        "\n",
        "    return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f-aYGNM2ceA"
      },
      "source": [
        "def classify_string(self,\n",
        "                    text: str) -> float:\n",
        "    \"\"\"\n",
        "    | Get the probability that a string is spam. Transforms the\n",
        "    | string into a TF-IDF vector and then returns self.model's\n",
        "    | prediction on the vector.\n",
        "    |\n",
        "    | ---------------------------------------------------------\n",
        "    | Parameters\n",
        "    | ----------\n",
        "    |  text : str\n",
        "    |    A raw string to be classified\n",
        "    \"\"\"\n",
        "    if not self.tfidf_vectorizer:\n",
        "        raise ValueError(\"Cannot generate predictions; must first \"\n",
        "                         \" set self.tfidf_vectorizer\")\n",
        "\n",
        "    vec = self.tfidf_vectorizer.transform([text])\n",
        "    return self.model.predict_proba(vec)[0][1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaxGV19o2fyC"
      },
      "source": [
        "**Flask App**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDcn2RXM2iuM"
      },
      "source": [
        "from flask import Flask, render_template, jsonify\n",
        "from static.python import SpamCatcher\n",
        "\n",
        "spam_catcher = SpamCatcher()\n",
        "spam_catcher.set_model(save_on_new=True)\n",
        "\n",
        "app = Flask(__name__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzAaPQaD2xfA"
      },
      "source": [
        "@app.route(\"/inspect\")\n",
        "def inspect():\n",
        "    return jsonify({'top_features': spam_catcher.top_features,\n",
        "                    'accuracy': spam_catcher.accuracy})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNDjmTG92nmB"
      },
      "source": [
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "\n",
        "@app.route(\"/about\")\n",
        "def about():\n",
        "    return render_template(\"about.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IBTr7w2ryh"
      },
      "source": [
        "@app.route(\"/inspect\")\n",
        "def inspect():\n",
        "    return jsonify({'top_features': spam_catcher.top_features,\n",
        "                    'accuracy': spam_catcher.accuracy})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpkojDL-20LU"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzJgemkq3AxN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}